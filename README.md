# MMGCL
Source code of our MMGCL

# Multi-modal Graph Contrastive Learning for Micro-video Recommendation

## Citation
If you want to use our codes and datasets in your research, please cite:
```
@inproceedings{yi2022multi,
  title={Multi-modal graph contrastive learning for micro-video recommendation},
  author={Yi, Zixuan and Wang, Xi and Ounis, Iadh and Macdonald, Craig},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1807--1811},
  year={2022}
}

```

## Environment
The codes of PGCL are implemented and tested under the following development environment:
* numba==0.53.1
* numpy==1.20.3
* scipy==1.6.2
* torch==1.10.3
* torch_scatter==2.0.6


## Usage
* Configure the xx.conf file in the directory named conf. (xx is the name of the model you want to run)</li>
* Run main.py and choose the model you want to run.</li>


## Datasets
You can find the full version of recommendation datasets via Tiktok, and Movielens. Since the copyright of datasets, we cannot release them directly.


## Update:
We tend to submit this to the multi modal recommendation library shortly.

